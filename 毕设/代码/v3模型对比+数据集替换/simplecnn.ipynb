{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0ee7ce-58a3-4293-992f-ca9fb97751e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 202M/202M [00:00<00:00, 389MiB/s]\n",
      "🍬  下载完成，正在解压...\n",
      "🏁  数据集已经成功添加\n"
     ]
    }
   ],
   "source": [
    "!featurize dataset download 0b3523e6-71ba-4e66-9fab-fa73ecc0f58c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c78770-a23d-409b-8c7d-428f6afaf3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting shap\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9e/3f/247e0017d52eeef37c170d71357eb3a12a2c06718d2e184c9929b6f3d9ed/shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /environment/miniconda3/lib/python3.10/site-packages (from shap) (1.24.1)\n",
      "Requirement already satisfied: scipy in /environment/miniconda3/lib/python3.10/site-packages (from shap) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn in /environment/miniconda3/lib/python3.10/site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in /environment/miniconda3/lib/python3.10/site-packages (from shap) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /environment/miniconda3/lib/python3.10/site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in /environment/miniconda3/lib/python3.10/site-packages (from shap) (23.0)\n",
      "Collecting slicer==0.0.7 (from shap)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba (from shap)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/13/b66627125b35f2987bd9872cf028b5e1e1ffcbc8d1e182ac4e84eed3998f/numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m157.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle (from shap)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/43/dae06432d0c4b1dc9e9149ad37b4ca8384cf6eb7700cd9215b177b914f0a/cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->shap)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/57/7d/ef28d5812f852b93bd2a583d00cdcde56833d31b645ae0eaa7e71eecfb4e/llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m146.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /environment/miniconda3/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas->shap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn->shap) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /environment/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Installing collected packages: slicer, llvmlite, cloudpickle, numba, shap\n",
      "Successfully installed cloudpickle-3.0.0 llvmlite-0.41.1 numba-0.58.1 shap-0.43.0 slicer-0.0.7\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in /environment/miniconda3/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /environment/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /environment/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scikit-learn in /environment/miniconda3/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /environment/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "!pip install pandas\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9775913f-597b-4fec-838c-ed8c39380d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------第1轮训练开始-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████████████████████████████████████████████████| 272/272 [00:33<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：272, Loss: 1.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试次数：68，Loss：123.2071\n",
      "1 test acc: 0.3620719424460432\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from resnet import resnet50 as self_resnet50\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from simple_cnn import SimpleCNN  # 引入SimpleCNN类\n",
    "\n",
    "\n",
    "# //////////////////////////////////////////////////////\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            files = os.listdir(class_path)\n",
    "            self.file_paths.extend([os.path.join(class_path, file) for file in files])\n",
    "            self.labels.extend([i] * len(files))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        data = np.loadtxt(file_path).reshape(32, 512)\n",
    "        data = torch.from_numpy(data).float()\n",
    "        return data, label\n",
    "    \n",
    "    def get_info(self, idx):\n",
    "        \"\"\" 返回文件路径和标签 \"\"\"\n",
    "        return self.file_paths[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置随机种子\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 数据集目录和文件路径\n",
    "    #'D:\\PychramProject\\transzero'\n",
    "    # data_dir = 'data/'\n",
    "    # C:\\Users\\ZHY\\Desktop\\data_txt\n",
    "    # data_dir = 'D:/PychramProject/transzero/data55-512/'\n",
    "    data_dir = 'data/datall/'\n",
    "    class_names = os.listdir(data_dir)\n",
    "\n",
    "    # 构建数据集\n",
    "    dataset = MyDataset(data_dir)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    # 创建数据加载器\n",
    "    batch_size = 256\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    # //////////////////////////////////////////////////////\n",
    "\n",
    "    model = SimpleCNN(num_classes=9)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 网络模型cuda\n",
    "    model = model.to(device)\n",
    "\n",
    "    # loss\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if torch.cuda.is_available():\n",
    "        loss_fn = loss_fn.cuda()\n",
    "\n",
    "\n",
    "    # optimizer\n",
    "    learning_rate = 0.01\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True, )\n",
    "\n",
    "\n",
    "    # 设置网络训练的一些参数\n",
    "    # 记录训练的次数\n",
    "    total_train_step = 0\n",
    "    # 记录测试的次数\n",
    "    total_test_step = 0\n",
    "    # 训练的轮数\n",
    "    epoch = 1\n",
    "\n",
    "    best_acc = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    probabilities = []\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(epoch):\n",
    "        print(\"-------第{}轮训练开始-------\".format(i + 1))\n",
    "        model.train()\n",
    "        # 训练步骤开始\n",
    "        for data in tqdm(train_dataloader, ncols=100, desc='Train'):\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():\n",
    "                # 图像cuda；标签cuda\n",
    "                # 训练集和测试集都要有\n",
    "                imgs = imgs.cuda()\n",
    "                targets = targets.cuda()\n",
    "            imgs = imgs.reshape(-1, 1, 32, 512)\n",
    "            # imgs1 = torch.cat((imgs, imgs), 1)\n",
    "            # imgs2 = torch.cat((imgs, imgs1), 1)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # 优化器优化模型\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_step = total_train_step + 1\n",
    "            # if total_train_step % 100 == 0:\n",
    "        print(\"训练次数：{}, Loss: {:.4f}\".format(total_train_step, loss.item()))\n",
    "                # writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "        # 测试集\n",
    "        # predictions = []\n",
    "        # targets = []\n",
    "        # probabilities = []\n",
    "        #\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            # test\n",
    "            total_correct = 0\n",
    "            total_num = 0\n",
    "\n",
    "            for data in test_dataloader:\n",
    "                imgs, targets = data\n",
    "                if torch.cuda.is_available():\n",
    "                    # 图像cuda；标签cuda\n",
    "                    # 训练集和测试集都要有\n",
    "                    imgs = imgs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                imgs = imgs.reshape(-1, 1, 32, 512)\n",
    "                # imgs1 = torch.cat((imgs, imgs), 1)\n",
    "                # imgs2 = torch.cat((imgs, imgs1), 1)\n",
    "                outputs = model(imgs)\n",
    "                #\n",
    "                # intermediate_layer = model.layer4[-1].conv3  # Modify this line to select the desired intermediate layer\n",
    "                # visualize_features(outputs)\n",
    "                #\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.tolist())\n",
    "                #\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                total_test_loss += loss.item()\n",
    "                total_test_step += 1\n",
    "\n",
    "                # logits = model(imgs)\n",
    "                logits = outputs\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct = torch.eq(pred, targets).float().sum().item()\n",
    "                total_correct += correct\n",
    "                total_num += imgs.size(0)\n",
    "                #\n",
    "                softmax = nn.Softmax(dim=1)\n",
    "                probs = softmax(outputs)\n",
    "                probabilities.extend(probs.tolist())\n",
    "\n",
    "\n",
    "                # if total_test_step % 100 == 0:\n",
    "            print(\"测试次数：{}，Loss：{:.4f}\".format(total_test_step, total_test_loss))\n",
    "            acc = total_correct / total_num\n",
    "            print(epoch, 'test acc:', acc)\n",
    "            #\n",
    "            # print(\"定性预测结果：\", predictions)\n",
    "            # print(\"定量预测结果：\", probabilities)\n",
    "            # 保存最优模型\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656394f-b04b-4281-8616-83f33fd6ba23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
